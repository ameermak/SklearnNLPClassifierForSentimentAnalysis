{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de0d4d59-5e97-46d5-8558-c5b9ce2baccf",
   "metadata": {},
   "source": [
    "# Amazon Books Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26487021-01d9-4fb8-8d01-21f77e3ef907",
   "metadata": {},
   "source": [
    "## Sentiment and Review Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55e22309-0068-4bff-ac1e-582c0573dc2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sentiment:\n",
    "    #Assigning sentiments to variable\n",
    "    POSITIVE = 'POSITIVE'\n",
    "    NEGATIVE = 'NEGATIVE'\n",
    "    NEUTRAL = 'NEUTRAL'\n",
    "\n",
    "class Review:\n",
    "    def __init__(self, text, score):\n",
    "        self.text = text\n",
    "        self.score = score\n",
    "        self.sentiment = self.get_sentiment()\n",
    "\n",
    "    def get_sentiment(self):\n",
    "        #Conditions for assigning sentiments\n",
    "        if self.score <= 2:\n",
    "            return Sentiment.NEGATIVE\n",
    "        elif self.score == 3:\n",
    "            return Sentiment.NEUTRAL\n",
    "        else: \n",
    "            #Score of 4 or 5\n",
    "            return Sentiment.POSITIVE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85109f2a-bd28-43df-a36f-97c1054ca12c",
   "metadata": {},
   "source": [
    "## Load Data From Json File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81b0443a-3d9f-484f-9f7e-f127acdef564",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"My Reflections:The well developed characters, the slow steady build all work together to deliver a tidy little package where mystery and history entwine.I loved the idea of a story centering on the decision, Franklyn Roosevelt devised to help people destroyed by the depression of 1935. His idea was to send families to a remote area of Alaska to colonies and grow the Matanuska Valley. The really superb thing about this book is these two authors use real and fictional characters to develop their narrative.Dr Jeremiah Vaughan's life is destroyed by allegations of abuse. When he uses a ground-breaking IV sedation technique with an influential patient, and the patient dies, the authorities are out for blood. This causes his license to be stripped away. Because of this, his intended and her mother want nothing to do with the shame. A has-been doctor is not what a high society woman wants on her arm. Fleeing from the hurt and rejection, from not only his fiance but also his own parents Jeremiah jumps at the chance to work alongside his mentor in a remote Alaskan village, far away from danger and pain...or so he thought.Gwyn is struggling with fear, rejection, and trust as she tends to her beloved village as a nurse. Her father (who is also the town's only doctor) is ecstatic at the prospect of seeing his village grow with the new colonization. As they race to ready the settlement for the new families, Gwyn must come to a place where she is able to accept the change and uncertainties of her future.This book was so surprising with it's villainous character and the twists and turns that ensued. It certainly was not the predictable book I imagined it to be.If you love fiction, history, romance, suspense you will probably enjoy this one. There are a few slow spots where the author is developing you knowledge of the characters, but by no means does it continue through the book. I will be keeping my eyes open for the sequel to this one.&#34;Book has been provided courtesy of Baker Publishing Group and Graf-Martin Communications, Inc.Available at your favourite bookseller from Bethany House, a division of Baker Publishing Group&#34;.\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "file_name = 'Books_10000.json'\n",
    "\n",
    "#Load file items into review list\n",
    "reviews = []\n",
    "with open(file_name) as f:\n",
    "    for line in f:\n",
    "        review = json.loads(line)\n",
    "        reviews.append(Review(review['reviewText'], review['overall']))\n",
    "\n",
    "reviews[30].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "325c1f98-d2d3-4e01-a1e8-31d93bcd89e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews[30].score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fcd64ffd-696c-4773-ba6e-5f5281590712",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NEUTRAL'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews[30].sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62781aba-0480-423e-b1d0-6ac254bce633",
   "metadata": {},
   "source": [
    "## Review Container Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "179e09a0-70cb-4a18-aad9-37194e4cf84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "class ReviewContainer:\n",
    "    def __init__(self, reviews):\n",
    "        self.reviews = reviews\n",
    "\n",
    "    def get_text(self):\n",
    "        return [x.text for x in self.reviews]\n",
    "\n",
    "    def get_sentiment(self):\n",
    "        return [x.sentiment for x in self.reviews]\n",
    "\n",
    "    def distribute(self):\n",
    "        #Evenly distributed positive and negative sentiments so that one sentiment is not more favoured than the other\n",
    "        positive = list(filter(lambda x: x.sentiment == Sentiment.POSITIVE, self.reviews))\n",
    "        negative = list(filter(lambda x: x.sentiment == Sentiment.NEGATIVE, self.reviews))\n",
    "        shrunk_positive = positive[:len(negative)]\n",
    "        self.reviews = shrunk_positive + negative\n",
    "        random.shuffle(self.reviews)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c089b500-a54f-47d4-8d09-e89ab11a0b9d",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4db57b8b-7fa0-4511-89e0-592521545533",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "training, test = train_test_split(reviews, test_size=0.33, random_state=42)\n",
    "\n",
    "#Assinging training and test data as a ReviewContainer class\n",
    "train_container = ReviewContainer(training)\n",
    "\n",
    "test_container = ReviewContainer(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc922dc2-b07e-4831-9158-5ed9712ff7df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "436\n",
      "436\n"
     ]
    }
   ],
   "source": [
    "train_container.distribute()\n",
    "\n",
    "#Splits training data into x and y variables(features and targets)\n",
    "train_x = train_container.get_text()\n",
    "train_y = train_container.get_sentiment()\n",
    "\n",
    "\n",
    "test_container.distribute()\n",
    "\n",
    "#Splits test data into x and y variables(features and targets)\n",
    "test_x = test_container.get_text()\n",
    "test_y = test_container.get_sentiment()\n",
    "\n",
    "print(train_y.count(Sentiment.POSITIVE))\n",
    "print(train_y.count(Sentiment.NEGATIVE))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4c8eb5-bde1-4237-b794-8709d4221182",
   "metadata": {},
   "source": [
    "## Bag of words Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45e79e9b-8e60-4d21-9377-bb2274edd604",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What kind of a society have we become that casually using the F-word in our stories is now mainstream? I hate it! It is a vulgar, nasty word. This is the 4th book this week I have started to read that casually uses the word. Why? For dramatic flair? To show your readers your unlimited vocabulary? To me, it just proves that the author wasn't able to come up with something more intelligent. I now hear foul language in the grocery store, in restaurants, walking down the streets, in our schools, it's everywhere! Why can't I sit down and enjoy a good story without it? We are bombarded with it everyday. Please keep it out of books! Please.\n",
      "[[0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "train_x_vectors = vectorizer.fit_transform(train_x)\n",
    "\n",
    "test_x_vectors = vectorizer.transform(test_x)\n",
    "\n",
    "print(train_x[0])\n",
    "print(train_x_vectors[0].toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3405d243-0ea2-434b-8c62-93088b6cd0c8",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ccffcb4e-c35e-451f-8d49-c31f06ba6693",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9141506f-0c94-40fa-a004-2c8e10d1ba72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sklearn ML pipeline\n",
    "pipelines = {\n",
    "    'rf':make_pipeline(RandomForestClassifier(random_state=42)),\n",
    "    'svm':make_pipeline(svm.SVC(random_state=42)),\n",
    "    'lr':make_pipeline(LogisticRegression(random_state=42)),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1c198bf6-3016-4744-abf8-84e83268fcf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'ccp_alpha': 0.0,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': None,\n",
       " 'max_features': 'sqrt',\n",
       " 'max_leaf_nodes': None,\n",
       " 'max_samples': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'monotonic_cst': None,\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': None,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RandomForestClassifier().get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3f945fdf-7351-41f7-9516-08fde7d7e19f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1.0,\n",
       " 'break_ties': False,\n",
       " 'cache_size': 200,\n",
       " 'class_weight': None,\n",
       " 'coef0': 0.0,\n",
       " 'decision_function_shape': 'ovr',\n",
       " 'degree': 3,\n",
       " 'gamma': 'scale',\n",
       " 'kernel': 'rbf',\n",
       " 'max_iter': -1,\n",
       " 'probability': False,\n",
       " 'random_state': None,\n",
       " 'shrinking': True,\n",
       " 'tol': 0.001,\n",
       " 'verbose': False}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm.SVC().get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2153ecd3-6f9d-4cc1-bee3-137a97f9cbbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1.0,\n",
       " 'class_weight': None,\n",
       " 'dual': False,\n",
       " 'fit_intercept': True,\n",
       " 'intercept_scaling': 1,\n",
       " 'l1_ratio': None,\n",
       " 'max_iter': 100,\n",
       " 'multi_class': 'auto',\n",
       " 'n_jobs': None,\n",
       " 'penalty': 'l2',\n",
       " 'random_state': None,\n",
       " 'solver': 'lbfgs',\n",
       " 'tol': 0.0001,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LogisticRegression().get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9eee2299-24b9-44ba-8eb4-f7679900b471",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dictionary to store hyperparameters\n",
    "hyparamgrid = {\n",
    "    'rf': {\n",
    "        'randomforestclassifier__min_samples_split':[2,4,6],\n",
    "        'randomforestclassifier__min_samples_leaf':[1,2,3]\n",
    "    },\n",
    "    'svm':{\n",
    "        'svc__kernel':['linear', 'rbf'],\n",
    "        'svc__C':[1,4,8,16,32]\n",
    "    },\n",
    "    'lr':{\n",
    "        'logisticregression__solver':['liblinear','lbfgs'],\n",
    "        'logisticregression__C':[1,4,8,16,32]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "29a62a60-ba7b-4bf7-ab6d-a0ef987aaadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.exceptions import NotFittedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "841c7703-35c2-41d0-9bb9-9100ea93f038",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training for rf.\n",
      "rf has been successfully fit.\n",
      "Starting training for svm.\n",
      "svm has been successfully fit.\n",
      "Starting training for lr.\n",
      "lr has been successfully fit.\n"
     ]
    }
   ],
   "source": [
    "#Dictionary to store fitted models \n",
    "fit_models = {}\n",
    "\n",
    "#For loops through piplines and uses GridSearchCV for hyperparameter tunning\n",
    "for algo, pipeline in pipelines.items():\n",
    "    model = GridSearchCV(pipeline, hyparamgrid[algo], cv=10, n_jobs=-1)\n",
    "    #Logging results while training models\n",
    "    try:\n",
    "        print('Starting training for {}.'.format(algo))\n",
    "        model.fit(train_x_vectors, train_y)\n",
    "        fit_models[algo] = model\n",
    "        print('{} has been successfully fit.'.format(algo))\n",
    "    except NotFittedError as e:\n",
    "        print(repr(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd2ef48f-f8e9-4b11-975b-b1e113b306eb",
   "metadata": {},
   "source": [
    "### Making Some Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a1dcb742-e58f-415b-b204-6471cbc58332",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a new set to test\n",
    "testing_set = ['very fun', 'bad book do not buy', 'horrible waste of time']\n",
    "new_test = vectorizer.transform(testing_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ef1ec94b-9b1f-4fff-a0ee-eb48df8c59ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['POSITIVE', 'NEGATIVE', 'NEGATIVE'], dtype='<U8')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_models['svm'].predict(new_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4a0cd619-346f-4da1-bea4-fc026bbe2760",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['POSITIVE', 'NEGATIVE', 'NEGATIVE'], dtype='<U8')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_models['rf'].predict(new_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "94d895b3-16cc-4b5c-804b-f575e1983092",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['POSITIVE', 'NEGATIVE', 'NEGATIVE'], dtype='<U8')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_models['lr'].predict(new_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "facecb5c-a4fa-465b-8982-b85058015bf4",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8f5c1578-efa8-4b96-a41c-0b6f11ebadc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rf scores - Accuracy: 0.7764423076923077\n",
      "svm scores - Accuracy: 0.8197115384615384\n",
      "lr scores - Accuracy: 0.8197115384615384\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "#Loop through and evaluate models performance\n",
    "for algo,model in fit_models.items():\n",
    "    yhat = model.predict(test_x_vectors)\n",
    "    print('{} scores - Accuracy: {}'.format(algo, metrics.accuracy_score(test_y, yhat)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a4c4125-3714-426b-8271-3533e5c8dbe3",
   "metadata": {},
   "source": [
    "### Random Forest Classification Report Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c9e9c323-67ce-4bb3-9a1e-4b31d0aa660d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[177  31]\n",
      " [ 62 146]]\n",
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    NEGATIVE       0.74      0.85      0.79       208\n",
      "    POSITIVE       0.82      0.70      0.76       208\n",
      "\n",
      "    accuracy                           0.78       416\n",
      "   macro avg       0.78      0.78      0.78       416\n",
      "weighted avg       0.78      0.78      0.78       416\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_predict_test = fit_models['rf'].predict(test_x_vectors)\n",
    "\n",
    "print('Confusion Matrix')\n",
    "print(metrics.confusion_matrix(test_y, rf_predict_test))\n",
    "print('')\n",
    "\n",
    "print('Classification Report')\n",
    "print(metrics.classification_report(test_y, rf_predict_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995fa5b4-365d-4c3e-8bed-4a4bb562eb9c",
   "metadata": {},
   "source": [
    "### Support Vector Machine Classification Report Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e7337985-3c96-4110-875f-fd375f57eaa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[167  41]\n",
      " [ 34 174]]\n",
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    NEGATIVE       0.83      0.80      0.82       208\n",
      "    POSITIVE       0.81      0.84      0.82       208\n",
      "\n",
      "    accuracy                           0.82       416\n",
      "   macro avg       0.82      0.82      0.82       416\n",
      "weighted avg       0.82      0.82      0.82       416\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm_predict_test = fit_models['svm'].predict(test_x_vectors)\n",
    "\n",
    "print('Confusion Matrix')\n",
    "print(metrics.confusion_matrix(test_y, svm_predict_test))\n",
    "print('')\n",
    "\n",
    "print('Classification Report')\n",
    "print(metrics.classification_report(test_y, svm_predict_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d97617-3a1b-44e3-ade7-1335d037f9bc",
   "metadata": {},
   "source": [
    "### Logistic Regression Classification Report Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "102313c9-06f1-4177-a639-b911c5c1e9f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[166  42]\n",
      " [ 33 175]]\n",
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    NEGATIVE       0.83      0.80      0.82       208\n",
      "    POSITIVE       0.81      0.84      0.82       208\n",
      "\n",
      "    accuracy                           0.82       416\n",
      "   macro avg       0.82      0.82      0.82       416\n",
      "weighted avg       0.82      0.82      0.82       416\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr_predict_test = fit_models['lr'].predict(test_x_vectors)\n",
    "\n",
    "print('Confusion Matrix')\n",
    "print(metrics.confusion_matrix(test_y, lr_predict_test))\n",
    "print('')\n",
    "\n",
    "print('Classification Report')\n",
    "print(metrics.classification_report(test_y, lr_predict_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff214b3-0992-498b-9988-fb7bd559d894",
   "metadata": {},
   "source": [
    "#### Support Vector Machine and Logistic Regression Models performed extremely similar, while Random Forest performed a bit worse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9af9164-5f65-44b1-98e3-1c18e9381658",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
